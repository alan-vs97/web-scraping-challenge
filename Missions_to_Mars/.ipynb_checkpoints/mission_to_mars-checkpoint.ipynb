{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open browser\n",
    "executable_path = {'executable_path': 'c:/chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA Updates Mars 2020 Mission Environmental Review\n",
      "NASA and the Department of Energy have completed a more detailed risk analysis for the Mars 2020 rover launch from Florida.\n"
     ]
    }
   ],
   "source": [
    "# Get data from news site\n",
    "\n",
    "url_news = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(url_news)\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find the first article\n",
    "news = soup.find('div', class_='list_text')\n",
    "\n",
    "\n",
    "# Find the title and the parragraph\n",
    "title_news = news.a.text\n",
    "p_news = news.find('div', class_='article_teaser_body').text\n",
    "\n",
    "print(title_news)\n",
    "print(p_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://photojournal.jpl.nasa.gov/jpeg/PIA18907.jpg\n"
     ]
    }
   ],
   "source": [
    "# Get image URL\n",
    "\n",
    "url_image = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(url_image)\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#print(soup.prettify())\n",
    "\n",
    "# Find the button that leads to the full image\n",
    "news = soup.find('a', class_='button fancybox')\n",
    "\n",
    "\n",
    "# Go to article with full image\n",
    "browser.visit(f\"https://www.jpl.nasa.gov/{news['data-link']}\")\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find list of download links\n",
    "images = soup.find_all('div', class_='download_tiff')\n",
    "\n",
    "# Find jpg format link\n",
    "for image in images:\n",
    "    if \"jpg\" in image.a['href']:\n",
    "        image_url = \"http:\" + image.a['href']\n",
    "\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InSight sol 351 (2019-11-22) low -100.4ºC (-148.7ºF) high -22.6ºC (-8.6ºF)\n",
      "winds from the SSE at 5.5 m/s (12.3 mph) gusting to 23.7 m/s (53.1 mph)\n",
      "pressure at 6.70 hPa\n"
     ]
    }
   ],
   "source": [
    "url_weather = 'https://twitter.com/marswxreport?lang=en'\n",
    "\n",
    "browser.visit(url_weather)\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#print(soup.prettify())\n",
    "\n",
    "# Find the first tweet in the timeline\n",
    "tweet = soup.find('div', class_=\"js-tweet-text-container\")\n",
    "\n",
    "# Get only the thext of the tweet, substracting the url of the image that came with the tweet\n",
    "weather_text = tweet.p.text.replace(tweet.p.a.text,\"\")\n",
    "print(weather_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "lxml not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-3de7842c5d64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#print(table.tbody)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\alanv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_default_na\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mdisplayed_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisplayed_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m     )\n",
      "\u001b[1;32mc:\\users\\alanv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[0;32m    886\u001b[0m     \u001b[0mretained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mflav\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflavor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompiled_match\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplayed_only\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alanv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parser_dispatch\u001b[1;34m(flavor)\u001b[0m\n\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_HAS_LXML\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 843\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lxml not found, please install it\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    844\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_valid_parsers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mflavor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: lxml not found, please install it"
     ]
    }
   ],
   "source": [
    "url_facts = 'https://space-facts.com/mars/'\n",
    "\n",
    "browser.visit(url_facts)\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#print(soup.prettify())\n",
    "\n",
    "# Find the first tweet in the timeline\n",
    "table = soup.find('table', class_=\"tablepress tablepress-id-p-mars\")\n",
    "\n",
    "#print(table.tbody)\n",
    "pd.read_html(table.tbody)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
